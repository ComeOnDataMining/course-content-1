{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W8 Homework",
      "provenance": [],
      "authorship_tag": "ABX9TyPpFGNUxm5AuaK2weCNX8xG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIS-522/course-content/blob/W8-homework/tutorials/W8_AutoEncoders_GANs/W8_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkhEz6Y17Q9c"
      },
      "source": [
        "# CIS-522 Week 8 Homework\n",
        "\n",
        "\n",
        "**Instructor:** Konrad Kording\n",
        "\n",
        "**Content Creators:** Richard Lange, Arash Ash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TEunJDE7wC7",
        "cellView": "form"
      },
      "source": [
        "#@markdown What is your Pennkey and pod? (text, not numbers, e.g. bfranklin)\n",
        "my_pennkey = 'bfranklin' #@param {type:\"string\"}\n",
        "my_pod = 'euclidean-wombat' #@param ['Select', 'euclidean-wombat', 'sublime-newt', 'buoyant-unicorn', 'lackadaisical-manatee','indelible-stingray','superfluous-lyrebird','discreet-reindeer','quizzical-goldfish','ubiquitous-cheetah','nonchalant-crocodile','fashionable-lemur','spiffy-eagle','electric-emu','quotidian-lion','astute-jellyfish', 'quantum-herring']\n",
        "\n",
        "# start timing\n",
        "import time\n",
        "try:t0;\n",
        "except NameError: t0 = time.time()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DQZZg1Fhj5y"
      },
      "source": [
        "We **strongly** recommend that you keep a separate document offline with your answers, and paste them in when you're ready to submit. Colab may reset and clear your notebook after a period of inactivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q001COb70H5"
      },
      "source": [
        "---\n",
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4czoj8Ll725j"
      },
      "source": [
        "from IPython.display import IFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSAYQpu475c9"
      },
      "source": [
        "# Part 1: build a VAE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_PIzQDB7_0L"
      },
      "source": [
        "Picking up where tutorial 1 left off: complete W8T1 Exercise 5. You may not be able to run multiple colab notebooks at once, so after completing the tutorial notebook, record some information for this assignment:\n",
        "\n",
        "1. Take a screenshot of the generated images. At the end of this homework, you'll upload your screenshot to airtable.\n",
        "2. Make a note of any changes you made to the architecture - you're encouraged (but not required) to experiment!\n",
        "3. Make a note of the value of the ELBO at the end of training.\n",
        "3. Make a note of `vae.sig_x` at the end of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ldUhAXuFpb7",
        "cellView": "form"
      },
      "source": [
        "#@markdown Which dataset did you train your VAE on?\n",
        "vae_dataset = \"other\" #@param [\"MNIST\", \"CIFAR\", \"other\"]\n",
        "#@markdown What dimensionality did you use for z (what is K)?\n",
        "vae_k_hidden = 20 #@param\n",
        "#@markdown How many convolutional filters did you use in each layer?\n",
        "vae_k_hidden = 32 #@param\n",
        "#@markdown What value did the ELBO converge to?\n",
        "vae_elbo = 0.0 #@param\n",
        "#@markdown After training, what was the value of `vae.sig_x`?\n",
        "vae_sig_x = 1.0 #@param\n",
        "#@markdown Did you experiment with the architecture in any other way? If so, what did you change?\n",
        "vae_changes = \"\" #@param{type:\"string\"}\n",
        "\n",
        "try:t1;\n",
        "except NameError: t1 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g1wQq118Aac"
      },
      "source": [
        "# Part 2: Know-a-pod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwtrWtDy8HzK"
      },
      "source": [
        " Discuss with two other members of your pod. What is an accomplishment that they are proud of, and why? (~100 words each)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63bbOM9hJkVC",
        "cellView": "form"
      },
      "source": [
        "know_a_pod_1 = \"\" #@param{type:\"string\"}\n",
        "know_a_pod_2 = \"\" #@param{type:\"string\"}\n",
        "\n",
        "try:t2;\n",
        "except NameError: t2 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx1UQGNA8Wxc"
      },
      "source": [
        "# Part 3: choose your own adventure\n",
        "\n",
        "Here you have a choice: either do Part 3a (if you lean towards theory and feel like reading a paper) or do Part 3b (if you lean towards engineering and want to do some data wrangling in Kaggle)\n",
        "\n",
        "## Part 3a: the bleeding edge of research\n",
        "\n",
        "You can choose between 3a and 3b.\n",
        "\n",
        "The field of \"deep generative models\" quite an active area of research! VAEs and GANs were both invented around 2014, and since then a steady stream of improvements and extensions have been developed, including thinkgs like WGAN and CycleGAN, which you've already seen.\n",
        "\n",
        "To get a sense of where the field is now, pick one of the following papers from the past few years. These papers can be quite dense, so it's not crucial that you understand every single step. With a bit of practice, you'll be able to read these papers and see at a glance what it's about at a high level. Don't spend more than an hour on this. \n",
        "\n",
        "Pick a paper from the list below and be prepared to answer the following high-level questions about it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SgY97Lb8tOW",
        "cellView": "form"
      },
      "source": [
        "#@markdown Which paper did you choose?\n",
        "paper_choice = \"Lastname et al (YEAR). Title.\" #@param{type:\"string\"}\n",
        "#@markdown In your own words, what is the problem that is addressed by this paper?\n",
        "paper_problem_addressed = \"\" #@param{type:\"string\"}\n",
        "#@markdown In your own words, what solution do the authors propose?\n",
        "paper_proposed_solution = \"\" #@param{type:\"string\"}\n",
        "#@markdown In your own words, how do they evaluate their solution to demonstrate that it works?\n",
        "paper_how_evaluated = \"\" #@param{type:\"string\"}\n",
        "#@markdown Any other thoughts? (What part still doesn't make sense? Was something particularly surprising? How might you extend it?)\n",
        "paper_miscellaneous = \"\" #@param{type:\"string\"}\n",
        "\n",
        "try:t3;\n",
        "except NameError: t3 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJIpH42OSe4c"
      },
      "source": [
        "__List of paper suggestions:__\n",
        "\n",
        "* Eslami et al (2018). \"Neural scene representation and rendering\" https://science.sciencemag.org/content/360/6394/1204.full\n",
        "* Brock et al (2018). \"Large Scale GAN Training for High Fidelity Natural Image Synthesis\" https://arxiv.org/abs/1809.11096\n",
        "* Gulrajani et al (2017). \"Improved Training of Wasserstein GANs\" https://arxiv.org/abs/1704.00028\n",
        "* Zhao et al (2017). \"InfoVAE: Information Maximizing Variational Autoencoders\" http://arxiv.org/abs/1706.02262\n",
        "* van den Oord et al (2017). \"Neural Discrete Representation Learning\" https://arxiv.org/abs/1711.00937\n",
        "* Higgins et al (2017). \"beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework\" https://openreview.net/forum?id=Sy2fzU9gl\n",
        "* Larsen et al (2016) \"Autoencoding beyond pixels using a learned similarity metric\" http://proceedings.mlr.press/v48/larsen16.html\n",
        "* Chen et al (2016) \"InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\" https://arxiv.org/abs/1606.03657\n",
        "* Gregor et al (2015) \"DRAW: A Recurrent Neural Network For Image Generation\" http://proceedings.mlr.press/v37/gregor15.html\n",
        "* Dziugaite et al (2015) \"Training generative neural networks via Maximum Mean Discrepancy optimization\" https://arxiv.org/abs/1505.03906\n",
        "* find one of your own!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BisrF3RmXVeT"
      },
      "source": [
        "## Part 3b: Kaggle\n",
        "\n",
        "You can choose between 3a and 3b.\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaZVd3xTpSjW"
      },
      "source": [
        "try:t4;\n",
        "except NameError: t4 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H1sYq198IPq"
      },
      "source": [
        "# Part 4: deep generative models and ethics\n",
        "\n",
        "First, for a sobering look at how generative models can be (mis)used, read [this Guardian article on DeepFakes](https://www.theguardian.com/technology/2020/jan/13/what-are-deepfakes-and-how-can-you-spot-them)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-s6R6fhhZF9",
        "cellView": "form"
      },
      "source": [
        "#@markdown Share your initial reaction (200-500 words). What was surprising? What was particularly frightening? Do you think this article over- or under-exaggerates the problem, or is it fair?\n",
        "deepfakes_initial_reaction = \"\" #@param{type:\"string\"}\n",
        "\n",
        "try:t5;\n",
        "except NameError: t5 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAzl6iczh6Av"
      },
      "source": [
        "For a more optimistic outlook on the promise of generative models and unsupervised learning, read [this OpenAI blog post](https://openai.com/blog/generative-models/).\n",
        "\n",
        "Recall the [cake analogy](https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae) from T1.\n",
        "\n",
        "<img width=\"500\" src=\"https://raw.githubusercontent.com/CIS-522/course-content/main/tutorials/W8_AutoEncoders_GANs/static/cake_clipart.png\" />\n",
        "\n",
        "Can we have our cake and eat it too? Can we create effective _unsupervised learning_ systems as the OpenAI article suggests _without_ also creating tools for automating and weaponizing misinformation, as in DeepFakes? If so, how? If not, do the benefits of unsupervised learning outweigh the costs? Share your thoughts in 300-500 words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "V6cEx80VlxYw"
      },
      "source": [
        "generative_models_costs_and_benefits = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown What are the responsibilities of individual AI researchers towards building ethical unsupervised learning and generative models? Is [openness always the answer](https://blogs.lse.ac.uk/impactofsocialsciences/2019/07/30/is-openness-in-ai-research-always-the-answer/)? Respond in 300-500 words.\n",
        "\n",
        "researcher_responsibilities = \"\" #@param{type:\"string\"}\n",
        "\n",
        "try:t6;\n",
        "except NameError: t6 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itbr5IuF85qz"
      },
      "source": [
        "---\n",
        "# Submit to Airtable\n",
        "**Don't forget to contribute to the conversation in your pod slack channel.** You can do so by copying and pasting some or all of the answers to the above questions, or by commenting and responding to other people's posts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9H-l0T68_XT",
        "cellView": "form"
      },
      "source": [
        "#@markdown #Run Cell to Show Airtable Form\n",
        "#@markdown ##**Confirm your answers and then click \"Submit\"**\n",
        "\n",
        "def prefill_form(src, fields: dict):\n",
        "  '''\n",
        "  src: the original src url to embed the form\n",
        "  fields: a dictionary of field:value pairs,\n",
        "  e.g. {\"pennkey\": my_pennkey, \"location\": my_location}\n",
        "  '''\n",
        "  prefills = \"&\".join([\"prefill_%s=%s\"%(key, fields[key]) for key in fields])\n",
        "  src = src + prefills\n",
        "  src = \"+\".join(src.split(\" \"))\n",
        "  return src\n",
        "\n",
        "#autofill fields if they are not present\n",
        "#a missing pennkey and pod will result in an Airtable warning\n",
        "#which is easily fixed user-side.\n",
        "try: my_pennkey;\n",
        "except NameError: my_pennkey = \"\"\n",
        "try: my_pod;\n",
        "except NameError: my_pod = \"Select\"\n",
        "\n",
        "times = [(t-t0) for t in [t1,t2,t3,t4,t5,t6]]\n",
        "\n",
        "fields = {\"pennkey\": my_pennkey,\n",
        "          \"pod\": my_pod,\n",
        "          \"vae_dataset\": vae_dataset,\n",
        "          \"vae_k_hidden\": vae_k_hidden,\n",
        "          \"vae_elbo\": vae_elbo,\n",
        "          \"vae_sig_x\": vae_sig_x,\n",
        "          \"vae_changes\": vae_changes,\n",
        "          \"know_a_pod_1\": know_a_pod_1,\n",
        "          \"know_a_pod_2\": know_a_pod_2,\n",
        "          \"paper_choice\": paper_choice,\n",
        "          \"paper_problem_addressed\": paper_problem_addressed,\n",
        "          \"paper_proposed_solution\": paper_proposed_solution,\n",
        "          \"paper_how_evaluated\": paper_how_evaluated,\n",
        "          \"paper_miscellaneous\": paper_miscellaneous,\n",
        "          \"deepfakes_initial_reaction\": deepfakes_initial_reaction,\n",
        "          \"generative_models_costs_and_benefits\": generative_models_costs_and_benefits,\n",
        "          \"researcher_responsibilities\": researcher_responsibilities,\n",
        "          \"cumulative_times\": times}\n",
        "\n",
        "src = \"https://airtable.com/embed/shrqbfoUrHoAg5Mza?\"\n",
        "\n",
        "#now instead of the original source url, we do: src = prefill_form(src, fields)\n",
        "display(IFrame(src = prefill_form(src, fields), width = 800, height = 400))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}